{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMl3ZZaMs0q_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "#get image\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "#draw on the image\n",
    "import numpy as np\n",
    "from PIL import Image as IMG\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "from IPython.display import Image as IMAGE\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This file is for constructing a data set consist of \"poo, pee, nothing\" dog image from video.\n",
    "First, get sequential frame images from the video and put it to the object detection model one by one.\n",
    "if the \"dog\" is detected, crop that part and put it as input to the pose decision model.\n",
    "according to the prediction result, save the image in the matching folder.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81235,
     "status": "ok",
     "timestamp": 1600489361247,
     "user": {
      "displayName": "방승연",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64",
      "userId": "18234865020509634221"
     },
     "user_tz": -540
    },
    "id": "yqkbIVGOuHa0",
    "outputId": "d578e7a5-c06a-4b46-a98e-fef1f61191a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# import module and obejct detector\n",
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0xzNgOZJUXX"
   },
   "outputs": [],
   "source": [
    "# function for showing image\n",
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(15, 10))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "# function that draws bounding box around the detected object\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "# function that calls \"draw_bounding_box_on_image\" when the \"dog\" is detected\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "  dog_coord = []\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      if (class_names[i].decode(\"ascii\") == \"Dog\") :\n",
    "        dog_coord.append([xmin, ymin, xmax, ymax])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = IMG.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  display_image(image)\n",
    "  \n",
    "  return dog_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmA_GrWdx5eW"
   },
   "outputs": [],
   "source": [
    "def run_detector(detector, img):\n",
    "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  result = detector(converted_img)\n",
    "  result = {key:value.numpy() for key,value in result.items()}\n",
    "  coord = draw_boxes(\n",
    "      img, result[\"detection_boxes\"],\n",
    "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "  return coord\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20364,
     "status": "ok",
     "timestamp": 1600490595297,
     "user": {
      "displayName": "방승연",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64",
      "userId": "18234865020509634221"
     },
     "user_tz": -540
    },
    "id": "v0iYhNaCOgVD",
    "outputId": "5035fcce-e5e8-461d-fb3f-921d686493c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pose decision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7F7_6NGRNWH"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('/content/gdrive/My Drive/soma/good_model/additional_train_4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjyrymXURzWf"
   },
   "outputs": [],
   "source": [
    "def createFolder(directory) :\n",
    "  try :\n",
    "    if not os.path.exists(directory) :\n",
    "      os.makedirs(directory)\n",
    "  except OSError :\n",
    "      print('Error : Creating dir : ' + directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87814,
     "status": "ok",
     "timestamp": 1600490723481,
     "user": {
      "displayName": "방승연",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64",
      "userId": "18234865020509634221"
     },
     "user_tz": -540
    },
    "id": "6QTFb3kQsxbm",
    "outputId": "5c695978-05ed-40c8-d27a-ab6d70e4de01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : /content/gdrive/My Drive/soma/vid/Dog Does Cartwheel While Peeing-RBtV6S4hkdo.mp4\n",
      "fps :  30.0\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"
     ]
    }
   ],
   "source": [
    "vid_num = 0\n",
    "image_x = 224\n",
    "image_y = 224\n",
    "\n",
    "for fname in glob.glob('/content/gdrive/My Drive/soma/vid/*.mp4') :\n",
    "  # try :\n",
    "    print(\"target : \"+ fname)\n",
    "    realname = fname.replace('/content/gdrive/My Drive/soma/vid/', \"\")\n",
    "    realname = realname.replace('.mp4', \"\")\n",
    "    fakename = realname[len(realname)-6:len(realname)] # generate folder with the unique video code\n",
    "\n",
    "    newfolder = '/content/gdrive/My Drive/soma/result/'+fakename\n",
    "    folder_o = newfolder+'/poo'\n",
    "    folder_e = newfolder+'/pee'\n",
    "    folder_n = newfolder+'/nothing'\n",
    "\n",
    "    dir_list = [newfolder, folder_o, folder_e, folder_n]\n",
    "\n",
    "    for p in dir_list :\n",
    "      createFolder(p)\n",
    "\n",
    "    texpath = os.path.join(newfolder, \"predict.txt\")\n",
    "    fid = open(texpath, \"a\")\n",
    "    fid.write(\"Time\\tPredicted\\tAnswer\\n\")\n",
    "\n",
    "    # get frames from the video\n",
    "    vidcap = cv2.VideoCapture(fname)\n",
    "    fps = vidcap.get(5)\n",
    "#     print(\"fps : \", fps)\n",
    "    vid_num += 1\n",
    "    count = 0\n",
    "    # to get 4 frames for each second\n",
    "    if (fps < 4) :\n",
    "      div = 1\n",
    "    else :\n",
    "      div = fps // 4\n",
    "    \n",
    "    while (vidcap.isOpened()) :\n",
    "      ret, image = vidcap.read()\n",
    "      if (ret == False) :\n",
    "        break\n",
    "      if (int(vidcap.get(1)) % div == 0) :\n",
    "        im2 = image.copy()\n",
    "        im2[:,:,0] = image[:,:,2]\n",
    "        im2[:,:,2] = image[:,:,0]\n",
    "        image = im2\n",
    "        # plt.imshow(image, aspect=\"auto\")\n",
    "        # plt.show()\n",
    "        \n",
    "        '''object detection'''\n",
    "        coord = run_detector(detector, image)\n",
    "        img = IMG.fromarray(image, 'RGB') # img = original image\n",
    "        w,h = img.size\n",
    "        temps = []\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if (coord == []) :\n",
    "          continue\n",
    "\n",
    "        for elem in coord :\n",
    "          temp = [0] * 4\n",
    "          temp[0] = elem[0] * w\n",
    "          temp[1] = elem[1] * h\n",
    "          temp[2] = elem[2] * w\n",
    "          temp[3] = elem[3] * h\n",
    "\n",
    "          y = temp[3] - temp[1]\n",
    "          x = temp[2] - temp[0]\n",
    "\n",
    "          if (x >= y) :\n",
    "            gap = x - y\n",
    "            gap = gap/2\n",
    "            temp[1] -= gap\n",
    "            temp[3] += gap\n",
    "          else :\n",
    "            gap = y - x\n",
    "            gap = gap /2\n",
    "            temp[0] -= gap\n",
    "            temp[2] += gap\n",
    "\n",
    "          temps.append(temp)\n",
    "        cropped_img = img.crop(temps[0])\n",
    "        final_img = cropped_img\n",
    "        # rescale\n",
    "        cropped_img = np.array(cropped_img, dtype=np.float32)\n",
    "        cropped_img = np.expand_dims(cropped_img, axis=0)\n",
    "        cropped_img = cropped_img/255.0\n",
    "\n",
    "        '''predict'''\n",
    "        pred_prob = model.predict(cropped_img)\n",
    "        pred_class = np.argmax(pred_prob)\n",
    "\n",
    "        classes = ['poo','nothing','pee']\n",
    "\n",
    "        # save file & write text file\n",
    "        if (pred_class == 0) : # predicted poo\n",
    "          newdir = folder_o + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n",
    "          final_img.save(newdir)\n",
    "          line = \"%0.2f\\tpoo\\t\\n\" %(count*0.25)\n",
    "          fid.write(line)\n",
    "\n",
    "        elif (pred_class == 1) : #predicted nothing\n",
    "          newdir = folder_n + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n",
    "          final_img.save(newdir)\n",
    "          line = \"%0.2f\\tnothing\\t\\n\" %(count*0.25)\n",
    "          fid.write(line)\n",
    "\n",
    "        elif (pred_class == 2) : # predicted pee\n",
    "          newdir = folder_e + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n",
    "          final_img.save(newdir)\n",
    "          line = \"%0.2f\\tpee\\t\\n\" %(count*0.25)\n",
    "          fid.write(line)\n",
    "\n",
    "        else :\n",
    "          print(\"prediction failed\")\n",
    "          line = \"%0.2f\\tX\\t\\n\" %(count*0.25)\n",
    "\n",
    "          fid.write(line)\n",
    "          \n",
    "\n",
    "        # print(\"frame #\" + str(count) + \" : \" + classes[pred_class])\n",
    "    fid.close()\n",
    "    vidcap.release()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNWvkZwe21Ier3u+O6T39eq",
   "collapsed_sections": [],
   "name": "getSequence_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
