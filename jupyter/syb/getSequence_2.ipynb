{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"getSequence_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWvkZwe21Ier3u+O6T39eq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CMl3ZZaMs0q_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","from google.colab import files\n","import glob\n","import cv2\n","from io import BytesIO\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","#get image\n","import matplotlib.pyplot as plt\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO\n","#draw on the image\n","import numpy as np\n","from PIL import Image as IMG\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","from IPython.display import Image as IMAGE\n","import os\n","import shutil\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqkbIVGOuHa0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600489361247,"user_tz":-540,"elapsed":81235,"user":{"displayName":"방승연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64","userId":"18234865020509634221"}},"outputId":"d578e7a5-c06a-4b46-a98e-fef1f61191a7"},"source":["module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n","\n","detector = hub.load(module_handle).signatures['default']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z0xzNgOZJUXX","colab_type":"code","colab":{}},"source":["def display_image(image):\n","  fig = plt.figure(figsize=(15, 10))\n","  plt.grid(False)\n","  plt.imshow(image)\n","\n","\n","\n","def draw_bounding_box_on_image(image,\n","                               ymin,\n","                               xmin,\n","                               ymax,\n","                               xmax,\n","                               color,\n","                               font,\n","                               thickness=4,\n","                               display_str_list=()):\n","  \"\"\"Adds a bounding box to an image.\"\"\"\n","  draw = ImageDraw.Draw(image)\n","  im_width, im_height = image.size\n","  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n","                                ymin * im_height, ymax * im_height)\n","  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n","             (left, top)],\n","            width=thickness,\n","            fill=color)\n","\n","  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n","  # Each display_str has a top and bottom margin of 0.05x.\n","  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n","\n","  if top > total_display_str_height:\n","    text_bottom = top\n","  else:\n","    text_bottom = top + total_display_str_height\n","  # Reverse list and print from bottom to top.\n","  for display_str in display_str_list[::-1]:\n","    text_width, text_height = font.getsize(display_str)\n","    margin = np.ceil(0.05 * text_height)\n","    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n","                    (left + text_width, text_bottom)],\n","                   fill=color)\n","    draw.text((left + margin, text_bottom - text_height - margin),\n","              display_str,\n","              fill=\"black\",\n","              font=font)\n","    text_bottom -= text_height - 2 * margin\n","\n","\n","def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n","  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n","  colors = list(ImageColor.colormap.values())\n","  dog_coord = []\n","\n","  try:\n","    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n","                              25)\n","  except IOError:\n","    print(\"Font not found, using default font.\")\n","    font = ImageFont.load_default()\n","\n","  for i in range(min(boxes.shape[0], max_boxes)):\n","    if scores[i] >= min_score:\n","      ymin, xmin, ymax, xmax = tuple(boxes[i])\n","      if (class_names[i].decode(\"ascii\") == \"Dog\") :\n","        dog_coord.append([xmin, ymin, xmax, ymax])\n","      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n","                                     int(100 * scores[i]))\n","      color = colors[hash(class_names[i]) % len(colors)]\n","      image_pil = IMG.fromarray(np.uint8(image)).convert(\"RGB\")\n","      np.copyto(image, np.array(image_pil))\n","  \n","  return dog_coord"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmA_GrWdx5eW","colab_type":"code","colab":{}},"source":["def run_detector(detector, img):\n","  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","  result = detector(converted_img)\n","\n","  result = {key:value.numpy() for key,value in result.items()}\n","\n","  coord = draw_boxes(\n","      img, result[\"detection_boxes\"],\n","      result[\"detection_class_entities\"], result[\"detection_scores\"])\n","\n","  # display_image(image_with_boxes)\n","  return coord\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0iYhNaCOgVD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600490595297,"user_tz":-540,"elapsed":20364,"user":{"displayName":"방승연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64","userId":"18234865020509634221"}},"outputId":"5035fcce-e5e8-461d-fb3f-921d686493c4"},"source":["drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W7F7_6NGRNWH","colab_type":"code","colab":{}},"source":["from tensorflow import keras\n","model = keras.models.load_model('/content/gdrive/My Drive/soma/good_model/additional_train_4/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjyrymXURzWf","colab_type":"code","colab":{}},"source":["def createFolder(directory) :\n","  try :\n","    if not os.path.exists(directory) :\n","      os.makedirs(directory)\n","  except OSError :\n","      print('Error : Creating dir : ' + directory)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frH8YDVSrOwm","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"6QTFb3kQsxbm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1600490723481,"user_tz":-540,"elapsed":87814,"user":{"displayName":"방승연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRFaBlSka099n-B7eOyYAUdultqz8a1oKzgk5d=s64","userId":"18234865020509634221"}},"outputId":"5c695978-05ed-40c8-d27a-ab6d70e4de01"},"source":["vid_num = 0\n","image_x = 224\n","image_y = 224\n","\n","for fname in glob.glob('/content/gdrive/My Drive/soma/vid/*.mp4') :\n","  # try :\n","    print(\"target : \"+ fname)\n","    realname = fname.replace('/content/gdrive/My Drive/soma/vid/', \"\")\n","    realname = realname.replace('.mp4', \"\")\n","    fakename = realname[len(realname)-6:len(realname)] # 뒤에 영상 코드만을 가지고 폴더 생성\n","\n","    newfolder = '/content/gdrive/My Drive/soma/result/'+fakename\n","    folder_o = newfolder+'/poo'\n","    folder_e = newfolder+'/pee'\n","    folder_n = newfolder+'/nothing'\n","\n","    dir_list = [newfolder, folder_o, folder_e, folder_n]\n","\n","    for p in dir_list :\n","      createFolder(p)\n","\n","    texpath = os.path.join(newfolder, \"predict.txt\")\n","    fid = open(texpath, \"a\")\n","    fid.write(\"Time\\tPredicted\\tAnswer\\n\")\n","\n","\n","    vidcap = cv2.VideoCapture(fname)\n","    fps = vidcap.get(5)\n","    print(\"fps : \", fps)\n","    vid_num += 1\n","    count = 0\n","    if (fps < 4) :\n","      div = 1\n","    else :\n","      div = fps // 4\n","    \n","    while (vidcap.isOpened()) :\n","      ret, image = vidcap.read()\n","      if (ret == False) :\n","        break\n","      if (int(vidcap.get(1)) % div == 0) :\n","        im2 = image.copy()\n","        im2[:,:,0] = image[:,:,2]\n","        im2[:,:,2] = image[:,:,0]\n","        image = im2\n","        # plt.imshow(image, aspect=\"auto\")\n","        # plt.show()\n","        \n","        # object detection\n","        coord = run_detector(detector, image)\n","        img = IMG.fromarray(image, 'RGB') # img = 원래 이미지\n","        w,h = img.size\n","        temps = []\n","\n","        count += 1\n","\n","        if (coord == []) :\n","          continue\n","\n","        for elem in coord :\n","          temp = [0] * 4\n","          temp[0] = elem[0] * w\n","          temp[1] = elem[1] * h\n","          temp[2] = elem[2] * w\n","          temp[3] = elem[3] * h\n","\n","          y = temp[3] - temp[1]\n","          x = temp[2] - temp[0]\n","\n","          if (x >= y) :\n","            gap = x - y\n","            gap = gap/2\n","            temp[1] -= gap\n","            temp[3] += gap\n","          else :\n","            gap = y - x\n","            gap = gap /2\n","            temp[0] -= gap\n","            temp[2] += gap\n","\n","          temps.append(temp)\n","        cropped_img = img.crop(temps[0])\n","        # cropped_img = cropped_img.resize((image_x, image_y))\n","        final_img = cropped_img\n","        \n","        # temp_name = folder_t+\"/\"+fakename+'_%0.2f.jpg' %(count*0.25)\n","        # final_img.save(temp_name)\n","        # cropped_img = tf.keras.preprocessing.image.load_img(temp_name)\n","        # cropped_img = tf.keras.preprocessing.image.img_to_array(cropped_img)\n","        cropped_img = np.array(cropped_img, dtype=np.float32)\n","        cropped_img = np.expand_dims(cropped_img, axis=0)\n","        cropped_img = cropped_img/255.0\n","\n","        # predict\n","        pred_prob = model.predict(cropped_img)\n","        pred_class = np.argmax(pred_prob)\n","        \n","        # print(\"pred : \"+ str(pred_class))\n","\n","        classes = ['poo','nothing','pee']\n","\n","        # save file & write text file\n","        # final_img = IMG.fromarray(cropped_img, 'RGB')\n","        \n","        if (pred_class == 0) : # predicted poo\n","          newdir = folder_o + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n","          final_img.save(newdir)\n","          line = \"%0.2f\\tpoo\\t\\n\" %(count*0.25)\n","          fid.write(line)\n","\n","        elif (pred_class == 1) : #predicted nothing\n","          newdir = folder_n + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n","          final_img.save(newdir)\n","          line = \"%0.2f\\tnothing\\t\\n\" %(count*0.25)\n","          fid.write(line)\n","\n","        elif (pred_class == 2) : # predicted pee\n","          newdir = folder_e + \"/\"+fakename + \"_%0.2f.jpg\" %(count*0.25)\n","          final_img.save(newdir)\n","          line = \"%0.2f\\tpee\\t\\n\" %(count*0.25)\n","          fid.write(line)\n","\n","        else :\n","          print(\"prediction failed\")\n","          line = \"%0.2f\\tX\\t\\n\" %(count*0.25)\n","\n","          fid.write(line)\n","          \n","\n","        # print(\"frame #\" + str(count) + \" : \" + classes[pred_class])\n","    fid.close()\n","    vidcap.release()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["target : /content/gdrive/My Drive/soma/vid/Dog Does Cartwheel While Peeing-RBtV6S4hkdo.mp4\n","fps :  30.0\n","WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 92, 92, 3).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"resnet50_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 83, 84, 3).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wlYOtD8EwPDi","colab_type":"code","colab":{}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilhjUxUE-Ckh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}